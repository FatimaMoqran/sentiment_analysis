{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = requests.get('https://redditmetrics.com/top')\n",
    "\n",
    "soup = BeautifulSoup(url.text, 'html.parser')\n",
    "with open('sb.txt', 'w' ) as f:\n",
    "    for subreddit in soup.find_all('a'):\n",
    "        try:\n",
    "            if '/r'  in subreddit.string:\n",
    "                f.write(subreddit.string[3:] + '\\n')\n",
    "        except:\n",
    "            TypeError "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/praw-dev/praw/archive/master.zip\n",
      "\u001b[?25l  Downloading https://github.com/praw-dev/praw/archive/master.zip (22.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 22.7MB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting prawcore<2.0,>=1.0.1 (from praw==6.3.2.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/76/b5/ce6282dea45cba6f08a30e25d18e0f3d33277e2c9fcbda75644b8dc0089b/prawcore-1.0.1-py2.py3-none-any.whl\n",
      "Collecting update_checker>=0.16 (from praw==6.3.2.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
      "Collecting websocket-client>=0.54.0 (from praw==6.3.2.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /home/fatima_moqran/anaconda3/lib/python3.7/site-packages (from prawcore<2.0,>=1.0.1->praw==6.3.2.dev0) (2.21.0)\n",
      "Requirement already satisfied: six in /home/fatima_moqran/anaconda3/lib/python3.7/site-packages (from websocket-client>=0.54.0->praw==6.3.2.dev0) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/fatima_moqran/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw==6.3.2.dev0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fatima_moqran/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw==6.3.2.dev0) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/fatima_moqran/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw==6.3.2.dev0) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/fatima_moqran/anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw==6.3.2.dev0) (2.8)\n",
      "Building wheels for collected packages: praw\n",
      "  Running setup.py bdist_wheel for praw ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-6zrqcgnw/wheels/5f/4a/b1/574031ec9fde90cdb1fbbeaa74043962e8452ebc763752ea79\n",
      "Successfully built praw\n",
      "Installing collected packages: prawcore, update-checker, websocket-client, praw\n",
      "Successfully installed praw-6.3.2.dev0 prawcore-1.0.1 update-checker-0.16 websocket-client-0.56.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install -- user praw\n",
    "!pip install --user https://github.com/praw-dev/praw/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " import praw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textblob in /home/fatima_moqran/.local/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /home/fatima_moqran/anaconda3/lib/python3.7/site-packages (from textblob) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/fatima_moqran/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: singledispatch in /home/fatima_moqran/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (3.4.0.3)\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /home/fatima_moqran/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/fatima_moqran/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/fatima_moqran/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/fatima_moqran/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /home/fatima_moqran/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/fatima_moqran/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -U textblob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting upgrade\n",
      "\u001b[31m  Could not find a version that satisfies the requirement upgrade (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for upgrade\u001b[0m\n",
      "6.3.2.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install --user upgrade praw\n",
    "\n",
    "!python -c 'import praw; print(praw.__version__)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submissions_pushshift_praw(subreddit, start=None, end=None, limit=100, extra_query=\"\"):\n",
    "    \"\"\"\n",
    "    A simple function that returns a list of PRAW submission objects during a particular period from a defined sub.\n",
    "    This function serves as a replacement for the now deprecated PRAW `submissions()` method.\n",
    "    \n",
    "    :param subreddit: A subreddit name to fetch submissions from.\n",
    "    :param start: A Unix time integer. Posts fetched will be AFTER this time. (default: None)\n",
    "    :param end: A Unix time integer. Posts fetched will be BEFORE this time. (default: None)\n",
    "    :param limit: There needs to be a defined limit of results (default: 100), or Pushshift will return only 25.\n",
    "    :param extra_query: A query string is optional. If an extra_query string is not supplied, \n",
    "                        the function will just grab everything from the defined time period. (default: empty string)\n",
    "    \n",
    "    Submissions are yielded newest first.\n",
    "    \n",
    "    For more information on PRAW, see: https://github.com/praw-dev/praw \n",
    "    For more information on Pushshift, see: https://github.com/pushshift/api\n",
    "    \"\"\"\n",
    "    matching_praw_submissions = []\n",
    "    \n",
    "    # Default time values if none are defined (credit to u/bboe's PRAW `submissions()` for this section)\n",
    "    utc_offset = 28800\n",
    "    now = int(time.time())\n",
    "    start = max(int(start) + utc_offset if start else 0, 0)\n",
    "    end = min(int(end) if end else now, now) + utc_offset\n",
    "    \n",
    "    # Format our search link properly.\n",
    "    search_link = ('https://api.pushshift.io/reddit/submission/search/'\n",
    "                   '?subreddit={}&after={}&before={}&sort_type=score&sort=asc&limit={}&q={}')\n",
    "    search_link = search_link.format(subreddit, start, end, limit, extra_query)\n",
    "    \n",
    "    # Get the data from Pushshift as JSON.\n",
    "    retrieved_data = requests.get(search_link)\n",
    "    returned_submissions = retrieved_data.json()['data']\n",
    "    \n",
    "    # Iterate over the returned submissions to convert them to PRAW submission objects.\n",
    "    for submission in returned_submissions:\n",
    "        \n",
    "        # Take the ID, fetch the PRAW submission object, and append to our list\n",
    "        praw_submission = reddit.submission(id=submission['id'])\n",
    "        matching_praw_submissions.append(praw_submission)\n",
    "     \n",
    "    # Return all PRAW submissions that were obtained.\n",
    "    return matching_praw_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/r/announcements\n",
      "No comment sentiment.\n",
      "\n",
      "/r/funny\n",
      "Ratio: 4\n",
      "\n",
      "/r/AskReddit\n",
      "Ratio: 7\n",
      "\n",
      "/r/gaming\n",
      "Ratio: 8\n",
      "\n",
      "/r/pics\n",
      "Ratio: 15\n",
      "\n",
      "/r/science\n",
      "Ratio: 9\n",
      "\n",
      "/r/worldnews\n",
      "Ratio: 7\n",
      "\n",
      "/r/aww\n",
      "Ratio: 17\n",
      "\n",
      "/r/todayilearned\n",
      "Ratio: 5\n",
      "\n",
      "/r/movies\n",
      "Ratio: 14\n",
      "\n",
      "/r/videos\n",
      "Ratio: 4\n",
      "\n",
      "/r/Music\n",
      "Ratio: 14\n",
      "\n",
      "/r/IAmA\n",
      "Ratio: 14\n",
      "\n",
      "/r/gifs\n",
      "Ratio: 8\n",
      "\n",
      "/r/news\n",
      "Ratio: 1\n",
      "\n",
      "/r/EarthPorn\n",
      "Ratio: 22\n",
      "\n",
      "/r/Showerthoughts\n",
      "Ratio: 6\n",
      "\n",
      "/r/askscience\n",
      "Ratio: 9\n",
      "\n",
      "/r/blog\n",
      "No comment sentiment.\n",
      "\n",
      "/r/Jokes\n",
      "Ratio: 6\n",
      "\n",
      "/r/explainlikeimfive\n",
      "Ratio: 12\n",
      "\n",
      "/r/books\n",
      "Ratio: 10\n",
      "\n",
      "/r/food\n",
      "Ratio: 35\n",
      "\n",
      "/r/LifeProTips\n",
      "Ratio: 9\n",
      "\n",
      "/r/DIY\n",
      "Ratio: 11\n",
      "\n",
      "/r/mildlyinteresting\n",
      "Ratio: 6\n",
      "\n",
      "/r/Art\n",
      "Ratio: 21\n",
      "\n",
      "/r/sports\n",
      "Ratio: 4\n",
      "\n",
      "/r/space\n",
      "Ratio: 9\n",
      "\n",
      "/r/gadgets\n",
      "Ratio: 13\n",
      "\n",
      "/r/nottheonion\n",
      "Ratio: 5\n",
      "\n",
      "/r/television\n",
      "Ratio: 7\n",
      "\n",
      "/r/photoshopbattles\n",
      "Ratio: 8\n",
      "\n",
      "/r/Documentaries\n",
      "Ratio: 10\n",
      "\n",
      "/r/listentothis\n",
      "Ratio: 18\n",
      "\n",
      "/r/GetMotivated\n",
      "Ratio: 15\n",
      "\n",
      "/r/UpliftingNews\n",
      "Ratio: 20\n",
      "\n",
      "/r/tifu\n",
      "Ratio: 4\n",
      "\n",
      "/r/InternetIsBeautiful\n",
      "No comment sentiment.\n",
      "\n",
      "/r/history\n",
      "Ratio: 5\n",
      "\n",
      "/r/Futurology\n",
      "Ratio: 7\n",
      "\n",
      "/r/philosophy\n",
      "No comment sentiment.\n",
      "\n",
      "/r/OldSchoolCool\n",
      "Ratio: 13\n",
      "\n",
      "/r/WritingPrompts\n",
      "Ratio: 11\n",
      "\n",
      "/r/personalfinance\n",
      "Ratio: 9\n",
      "\n",
      "/r/dataisbeautiful\n",
      "Ratio: 11\n",
      "\n",
      "/r/nosleep\n",
      "Ratio: 13\n",
      "\n",
      "/r/creepy\n",
      "No comment sentiment.\n",
      "\n",
      "/r/TwoXChromosomes\n",
      "Ratio: 8\n",
      "\n",
      "/r/technology\n",
      "Ratio: 4\n",
      "\n",
      "/r/AdviceAnimals\n",
      "Ratio: 13\n",
      "\n",
      "/r/Fitness\n",
      "Ratio: 10\n",
      "\n",
      "/r/memes\n",
      "Ratio: 8\n",
      "\n",
      "/r/WTF\n",
      "Ratio: 5\n",
      "\n",
      "/r/politics\n",
      "Ratio: 6\n",
      "\n",
      "/r/wholesomememes\n",
      "Ratio: 7\n",
      "\n",
      "/r/bestof\n",
      "Ratio: 4\n",
      "\n",
      "/r/interestingasfuck\n",
      "Ratio: 11\n",
      "\n",
      "/r/BlackPeopleTwitter\n",
      "Ratio: 3\n",
      "\n",
      "/r/oddlysatisfying\n",
      "Ratio: 7\n",
      "\n",
      "/r/leagueoflegends\n",
      "Ratio: 9\n",
      "\n",
      "/r/lifehacks\n",
      "Ratio: 25\n",
      "\n",
      "/r/travel\n",
      "Ratio: 18\n",
      "\n",
      "/r/pcmasterrace\n",
      "Ratio: 10\n",
      "\n",
      "/r/facepalm\n",
      "Ratio: 4\n",
      "\n",
      "/r/dankmemes\n",
      "Ratio: 1\n",
      "\n",
      "/r/me_irl\n",
      "Ratio: 9\n",
      "\n",
      "/r/woahdude\n",
      "Ratio: 14\n",
      "\n",
      "/r/PS4\n",
      "Ratio: 6\n",
      "\n",
      "/r/NatureIsFuckingLit\n",
      "Ratio: 11\n",
      "\n",
      "/r/Tinder\n",
      "Ratio: 5\n",
      "\n",
      "/r/nba\n",
      "Ratio: 5\n",
      "\n",
      "/r/relationships\n",
      "Ratio: 7\n",
      "\n",
      "/r/AnimalsBeingBros\n",
      "Ratio: 11\n",
      "\n",
      "/r/AnimalsBeingJerks\n",
      "Ratio: 9\n",
      "\n",
      "/r/Overwatch\n",
      "Ratio: 9\n",
      "\n",
      "/r/tattoos\n",
      "Ratio: 25\n",
      "\n",
      "/r/Whatcouldgowrong\n",
      "Ratio: 6\n",
      "\n",
      "/r/atheism\n",
      "Ratio: 10\n",
      "\n",
      "/r/reactiongifs\n",
      "Ratio: -7\n",
      "\n",
      "/r/FoodPorn\n",
      "Ratio: 21\n",
      "\n",
      "/r/trippinthroughtime\n",
      "Ratio: 0\n",
      "\n",
      "/r/gameofthrones\n",
      "Ratio: 8\n",
      "\n",
      "/r/programming\n",
      "Ratio: 22\n",
      "\n",
      "/r/BikiniBottomTwitter\n",
      "Ratio: 8\n",
      "\n",
      "/r/gonewild\n",
      "Ratio: 23\n",
      "\n",
      "/r/Unexpected\n",
      "Ratio: 8\n",
      "\n",
      "/r/malefashionadvice\n",
      "Ratio: 2\n",
      "\n",
      "/r/europe\n",
      "Ratio: 4\n",
      "\n",
      "/r/boardgames\n",
      "Ratio: 0\n",
      "\n",
      "/r/PewdiepieSubmissions\n",
      "Ratio: 7\n",
      "\n",
      "/r/gardening\n",
      "Ratio: 12\n",
      "\n",
      "/r/pokemongo\n",
      "Ratio: 11\n",
      "\n",
      "/r/relationship_advice\n",
      "Ratio: 7\n",
      "\n",
      "/r/instant_regret\n",
      "Ratio: 12\n",
      "\n",
      "/r/photography\n",
      "Ratio: 24\n",
      "\n",
      "/r/Games\n",
      "Ratio: 6\n",
      "\n",
      "/r/dadjokes\n",
      "Ratio: 7\n",
      "\n",
      "/r/loseit\n",
      "Ratio: 9\n",
      "\n",
      "/r/iphone\n",
      "Ratio: 14\n",
      "\n",
      "/r/TrendingReddits\n",
      "No comment sentiment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id = 'nL_YtxBQVywXkg',\n",
    "                    client_secret = 'LAb6r8D-yLEQeXLBtYxKxx6lQYs',\n",
    "                    user_agent='subSentiment')\n",
    "with open('sb.txt') as f:\n",
    "    day_start = 1568332800\n",
    "    day_end = 1568419140\n",
    "    \n",
    "    for line in f:\n",
    "        subreddit = reddit.subreddit(line.strip())\n",
    "        sub_submissions = submissions_pushshift_praw(subreddit,start = day_start, end = day_end,limit=100, extra_query=\"\")\n",
    "        sub_sentiment = 0\n",
    "        num_comments = 0\n",
    "        \n",
    "        for submission in sub_submissions:\n",
    "            if not submission.stickied:\n",
    "                submission.comments.replace_more(limit=0)\n",
    "                for comment in submission.comments.list():\n",
    "                    blob = TextBlob(comment.body)\n",
    "                    \n",
    "                    comment_sentiment = blob.sentiment.polarity\n",
    "                    sub_sentiment += comment_sentiment\n",
    "                    \n",
    "                    num_comments += 1\n",
    "        print('/r/' + str(subreddit.display_name))\n",
    "        try:\n",
    "            print('Ratio: '  + str(math.floor(sub_sentiment/num_comments * 100)) + '\\n')\n",
    "        except:\n",
    "            print('No comment sentiment.' +'\\n')\n",
    "            ZeroDivisionError\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob2 = TextBlob(\"Analytics Vidhya is a great platform to learn data science. \\n It helps community through blogs, hackathons, discussions,etc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"“I’d happy pay $1,500“ I don’t know if you can’t read but he said the pro doesn’t have 90hz screen even 120hz blah blah blah it’s all in his post\")]\n",
      "“\n",
      "I\n",
      "’\n",
      "d\n",
      "happy\n",
      "pay\n",
      "1,500\n",
      "“\n",
      "I\n",
      "don\n",
      "’\n",
      "t\n",
      "know\n",
      "if\n",
      "you\n",
      "can\n",
      "’\n",
      "t\n",
      "read\n",
      "but\n",
      "he\n",
      "said\n",
      "the\n",
      "pro\n",
      "doesn\n",
      "’\n",
      "t\n",
      "have\n",
      "90hz\n",
      "screen\n",
      "even\n",
      "120hz\n",
      "blah\n",
      "blah\n",
      "blah\n",
      "it\n",
      "’\n",
      "s\n",
      "all\n",
      "in\n",
      "his\n",
      "post\n"
     ]
    }
   ],
   "source": [
    "print(blob.sentences)\n",
    "\n",
    "for words in blob.sentences[0].words:\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’ d\n",
      "don ’ t\n",
      "’ t\n",
      "pro doesn ’ t\n",
      "90hz screen\n",
      "120hz blah blah blah\n",
      "’ s\n"
     ]
    }
   ],
   "source": [
    "for np in blob.noun_phrases:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“ NN\n",
      "I PRP\n",
      "’ VBP\n",
      "d JJ\n",
      "happy JJ\n",
      "pay NN\n",
      "1,500 CD\n",
      "“ NNP\n",
      "I PRP\n",
      "don VBP\n",
      "’ JJ\n",
      "t NN\n",
      "know VBP\n",
      "if IN\n",
      "you PRP\n",
      "can MD\n",
      "’ VB\n",
      "t JJ\n",
      "read NN\n",
      "but CC\n",
      "he PRP\n",
      "said VBD\n",
      "the DT\n",
      "pro JJ\n",
      "doesn NN\n",
      "’ NN\n",
      "t NN\n",
      "have VBP\n",
      "90hz CD\n",
      "screen JJ\n",
      "even RB\n",
      "120hz CD\n",
      "blah NNS\n",
      "blah RB\n",
      "blah VBP\n",
      "it PRP\n",
      "’ VBZ\n",
      "s JJ\n",
      "all DT\n",
      "in IN\n",
      "his PRP$\n",
      "post NN\n"
     ]
    }
   ],
   "source": [
    "for words, tag in blob.tags:\n",
    "    print(words, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n"
     ]
    }
   ],
   "source": [
    "print(blob.sentences[0].words[4].singularize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“I’d happy pay $1,500“ I don’t know if you can’t read but he said the pro doesn’t have 90hz screen even 120hz blah blah blah it’s all in his post\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.8, subjectivity=1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(blob)\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"«Je serais heureux de payer 1 500 dollars» «Je ne sais pas si vous savez lire, mais il a dit que le pro n’a pas d’écran à 90hz, même à 120hz. Blah blah blah c’est tout dans son message.\")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.translate(from_lang='en', to = 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [\n",
    "('Tom Holland is a terrible spiderman.','pos'),\n",
    "('a terrible Javert (Russell Crowe) ruined Les Miserables for me...','pos'),\n",
    "('The Dark Knight Rises is the greatest superhero movie ever!','neg'),\n",
    "('Fantastic Four should have never been made.','pos'),\n",
    "('Wes Anderson is my favorite director!','neg'),\n",
    "('Captain America 2 is pretty awesome.','neg'),\n",
    "('Let\\s pretend \"Batman and Robin\" never happened..','pos'),\n",
    "]\n",
    "testing = [\n",
    "('Superman was never an interesting character.','pos'),\n",
    "('Fantastic Mr Fox is an awesome film!','neg'),\n",
    "('Dragonball Evolution is simply terrible!!','pos')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import classifiers\n",
    "classifier = classifiers.NaiveBayesClassifier(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## decision tree classifier\n",
    "dt_classifier = classifiers.DecisionTreeClassifier(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Most Informative Features\n",
      "            contains(is) = True              neg : pos    =      2.9 : 1.0\n",
      "         contains(never) = False             neg : pos    =      1.8 : 1.0\n",
      "      contains(terrible) = False             neg : pos    =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print (classifier.accuracy(testing))\n",
    "classifier.show_informative_features(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
